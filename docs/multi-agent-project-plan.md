# Multi-Agent Dev/Test Automation Plan

## 1. Project Objectives
- Automate the full web app development and QA loop using three collaborating agents.
- Generate a small multi-page (2–3 pages) web experience directly from written requirements.
- Produce Playwright end-to-end test coverage that traces core user flows described in the requirements.
- Execute the generated tests through the Playwright MCP tool and report structured results.

## 2. Scope and Deliverables
- **Requirements Input**: A human-authored requirements file (Markdown or plain text) located in a dedicated folder (e.g., `requirements/feature-request.md`).
- **Deliverable 1**: Generated web project files under `web-app/` (HTML/CSS/JS or preferred framework) created by Agent 1.
- **Deliverable 2**: Playwright test specs generated by Agent 2 under `playwright-mcp/tests/`.
- **Deliverable 3**: Automated execution report (console output + optional structured JSON summary) produced by Agent 3 via the Playwright MCP tool.
- **Out of Scope (initial phase)**: CI/CD integration, deployment to hosting, advanced analytics. Those can be backlog items.

## 3. High-Level Agent Responsibilities
1. **Requirements-to-Web Agent**
   - Inputs: requirements file path, tech stack preference (HTML/CSS/JS baseline), design constraints.
   - Tasks: parse requirements, scaffold project (e.g., Vite/React or vanilla HTML depending on constraints), generate components/pages, produce README summarizing implementation.
   - Outputs: web codebase, list of implemented requirements, TODOs for ambiguous items.

2. **Code Analysis & Test Authoring Agent**
   - Inputs: generated web codebase, requirement artifacts, implementation summary from Agent 1.
   - Tasks: identify critical user journeys, map them to Playwright tests, ensure selectors stable, document assumptions, optionally lint or run basic static checks.
   - Outputs: Playwright test suite files, testing README with instructions, risk assessment for uncovered areas.

3. **QA Runner Agent (Playwright MCP Integrator)**
   - Inputs: Playwright test suite path, optional environment config, MCP tool handle.
   - Tasks: invoke Playwright MCP to install deps (if needed), run tests, capture pass/fail with logs and screenshots on failure, summarize results.
   - Outputs: console report, machine-readable summary (JSON/markdown), artifacts saved under `playwright-mcp/test-results/`.

## 4. System Architecture Overview
- **Agent Framework**: Use `agent_framework` primitives already in repo (e.g., `AzureOpenAIAssistantsClient`, `AnthropicClient`).
- **Coordination Layer**: Orchestrator script (e.g., `main.py`) that sequentially triggers agents and passes artifacts.
- **Storage Layout**:
  - `requirements/` — input specs.
  - `web-app/` — generated site source.
  - `playwright-mcp/tests/` — generated Playwright specs.
  - `playwright-mcp/test-results/` — execution outputs (JUnit, screenshots, video optional).
  - `logs/` — agent conversation transcripts for debugging.
- **MCP Integration**: Use `create_playwright_mcp_tool()` already present to run tests. Extend to accept dynamic working directory and config.

## 5. Detailed Implementation Steps
1. **Repository Prep**
   - Add `requirements/` directory with sample requirement file for testing.
   - Ensure `.env` template lists Anthropic/Azure credentials and any web app config.
   - Update README with project purpose and how to trigger orchestration script.

2. **Agent 1 Development**
   - Implement requirement parser utility that extracts pages, components, forms, validation rules.
   - Define prompt template guiding Agent 1 to output:
     - File diff instructions or direct file contents.
     - Coverage matrix mapping requirements → implementation.
   - Decide on default stack (e.g., Vite + React + Tailwind) unless requirement specifies otherwise.
   - Add safeguards: enforce 2–3 page limit, include navigation, responsive layout basics.

3. **Agent 2 Development**
   - Implement code analysis routine to gather DOM structure, routes, and data attributes for stable selectors.
   - Create prompt template instructing test author agent to:
     - Cover happy paths plus validation edge cases highlighted in requirements.
     - Use deterministic selectors (data-testid) and request Agent 1 to add them if missing.
     - Output tests in Playwright TS or JS (align with project preference) plus utility functions.
   - Generate test plan summary prior to code output, enabling human review.

4. **Agent 3 Development**
   - Extend existing `run_playwright_agent` pipeline to accept dynamic prompts for executing generated tests.
   - Add functionality to capture Playwright MCP output, parse pass/fail, and persist results.
   - Provide retry logic and environment variable validation.

5. **Orchestration Flow**
   - Create orchestrator script that:
     1. Loads requirements file and context.
     2. Calls Agent 1; commits or saves output.
     3. Calls Agent 2 with pointers to generated code.
     4. Instructs Agent 3 to run tests via MCP.
     5. Aggregates summary (requirements coverage, test coverage, execution status).
   - Include CLI flags to run specific stages (`--build`, `--test`, `--run-tests`) for debugging.

6. **Testing & Validation**
   - Create manual acceptance checklist ensuring requirements traceable to UI components and tests.
   - Implement smoke tests for orchestration script (e.g., using pytest async tests with mocks).
   - Document failure handling (e.g., missing environment variables, Playwright installation issues).

7. **Documentation & Tooling**
   - Provide user guide in `docs/usage.md` for running full pipeline.
   - Document how to extend agents (change models, adjust prompts).
   - Include troubleshooting tips for MCP connectivity (Node version, Playwright dependencies).

## 6. Backlog and Future Enhancements
- Add CI pipeline (GitHub Actions) to run orchestration in headless mode.
- Introduce code quality agent for linting and accessibility checks.
- Support alternative front-end stacks (Next.js, Svelte) based on requirement metadata.
- Implement conversational interface to refine requirements iteratively.
- Store agent outputs and decisions in Vector DB for learning.

## 7. Acceptance Criteria
- Running the orchestrator with a sample requirements file produces:
  1. A functional 2–3 page web app meeting the documented requirements.
  2. Playwright tests that pass locally against the generated app.
  3. A consolidated summary indicating success/fail for each requirement and test.
- Documentation explains setup steps and how to swap models/providers.

## 8. Next Immediate Actions
1. Confirm technology stack preference for generated web app (vanilla vs React).
2. Add sample requirements document for initial development.
3. Scaffold orchestrator script structure and stub agent functions.
4. Validate Playwright MCP tool locally (`npx -y @playwright/mcp@latest --help`).
